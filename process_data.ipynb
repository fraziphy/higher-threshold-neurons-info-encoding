{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5152ff16-3405-49a8-81f8-05e6b64c4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fa62164-7536-4b09-af1b-714dd8a0984a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spikes_to_matrix(spike_list, n_steps, N, step_size):\n",
    "    \"\"\"\n",
    "    Convert spike data into a spike matrix.\n",
    "\n",
    "    Args:\n",
    "        spike_list (list): List of spikes [(time, neuron_id), ...].\n",
    "        n_steps (int): Number of time steps.\n",
    "        N (int): Number of neurons.\n",
    "        step_size (float): Time step size in ms.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Spike matrix of shape (n_steps, N).\n",
    "    \"\"\"\n",
    "    spike_matrix = np.zeros((n_steps, N))\n",
    "    for spike_time, neuron_id in spike_list:\n",
    "        time_bin = int(spike_time / step_size)\n",
    "        if 0 <= time_bin < n_steps and 0 <= neuron_id < N:\n",
    "            spike_matrix[time_bin, neuron_id] += 1\n",
    "    return spike_matrix\n",
    "\n",
    "\n",
    "def compute_participation_ratio(spike_matrix):\n",
    "    # Center the data\n",
    "    centered_matrix = spike_matrix - np.mean(spike_matrix, axis=0, keepdims=True)\n",
    "    \n",
    "    # Compute SVD\n",
    "    _, s, _ = np.linalg.svd(centered_matrix, full_matrices=False)\n",
    "    \n",
    "    # Compute participation ratio\n",
    "    participation_ratio = (np.sum(s**2)**2) / np.sum(s**4)\n",
    "    \n",
    "    return participation_ratio\n",
    "\n",
    "\n",
    "\n",
    "def generate_heterogeneous_thresholds(V_th_mean, V_th_std, N, rng):\n",
    "    \"\"\"\n",
    "    Generate heterogeneous threshold potentials for N neurons.\n",
    "    \"\"\"\n",
    "    if V_th_std == 0:\n",
    "        V_th = np.full(N, V_th_mean)\n",
    "    else:\n",
    "        V_th = rng.uniform(V_th_mean - V_th_std * np.sqrt(3),\n",
    "                           V_th_mean + V_th_std * np.sqrt(3), N)\n",
    "    return V_th\n",
    "\n",
    "\n",
    "\n",
    "def fft_convolution_with_padding(signal, kernel):\n",
    "    \"\"\"\n",
    "    Perform linear convolution using FFT with proper zero-padding.\n",
    "\n",
    "    Args:\n",
    "        signal (numpy.ndarray): Input signal.\n",
    "        kernel (numpy.ndarray): Impulse response or kernel.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: Linearly convolved signal.\n",
    "    \"\"\"\n",
    "    padded_length = len(signal) + len(kernel) - 1\n",
    "    padded_signal = np.pad(signal, (0, padded_length - len(signal)))\n",
    "    padded_kernel = np.pad(kernel, (0, padded_length - len(kernel)))\n",
    "\n",
    "    convolved = np.fft.ifft(np.fft.fft(padded_signal) * np.fft.fft(padded_kernel))\n",
    "\n",
    "    return np.real(convolved[:len(signal)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a6806b7-1dbb-478b-a980-ee3d063af796",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_input_bumps(duration_ms, n_input_neurons, dt, noise_std=0.2):\n",
    "    \"\"\"\n",
    "    Generate a potential with two large bumps at the edges and a smaller, lower bump in the middle.\n",
    "\n",
    "    Parameters:\n",
    "    x: array of x values\n",
    "    a: controls the position of the bumps\n",
    "    b: controls the width of the potential\n",
    "    max_height: height of the outer peaks\n",
    "    mid_height: height of the middle peak (should be less than max_height)\n",
    "    dip: how much to pull down the middle section\n",
    "    \"\"\"\n",
    "    a=1.0\n",
    "    b=2.0\n",
    "    max_height=3.0\n",
    "    mid_height=0.8\n",
    "    dip=0.3\n",
    "\n",
    "    num_samples = int(duration_ms / dt)\n",
    "    x = np.linspace(-2, 2, num_samples)\n",
    "    # Ensure mid_height is less than max_height\n",
    "    mid_height = min(mid_height, max_height - 0.5)\n",
    "\n",
    "    # Create the basic shape with three bumps\n",
    "    V = max_height * (np.exp(-(x+a)**2/0.4) + np.exp(-(x-a)**2/0.2)) + mid_height * np.exp(-x**2/0.4)\n",
    "\n",
    "    # Pull down the middle section\n",
    "    # V -= dip * np.exp(-x**2/40)\n",
    "\n",
    "    # Ensure it goes to zero at the edges\n",
    "    V *= (1 - (x/b)**2)**2\n",
    "\n",
    "    # Normalize to ensure max_height is reached\n",
    "    V *= max_height / np.max(V)\n",
    "\n",
    "    # Ensure no negative values\n",
    "    V = np.maximum(V, 0)\n",
    "\n",
    "    current = V\n",
    "\n",
    "    return current\n",
    "\n",
    "\n",
    "\n",
    "def generate_input_sine(duration_ms, n_input_neurons, dt, amplitude=2, noise_std=0.2):\n",
    "    \"\"\"\n",
    "    Generate sinusoidal current with Gaussian noise for input neurons.\n",
    "\n",
    "    Parameters:\n",
    "    duration_ms (float): Duration of the simulation in milliseconds\n",
    "    input_neurons_dyn (numpy.ndarray): Array of neuron indices receiving dynamic input\n",
    "    amplitude (float): Amplitude of the sine wave (default: 0.5)\n",
    "    noise_std (float): Standard deviation of the Gaussian noise (default: 0.1)\n",
    "\n",
    "    Returns:\n",
    "    numpy.ndarray: Normalized current for each input neuron\n",
    "\n",
    "    Global variables used:\n",
    "    dt (float): Time step in milliseconds\n",
    "    \"\"\"\n",
    "    num_samples = int(duration_ms / dt)\n",
    "    time = np.arange(num_samples) * dt\n",
    "\n",
    "    # Generate base sine wave with a period of 400 ms\n",
    "    frequency = 2.5  # 2.5 Hz for 400 ms period\n",
    "    base_sine = amplitude * np.sin(2 * np.pi * frequency * time / 1000)\n",
    "\n",
    "    # Keep only the upper half of the sine wave\n",
    "    current = np.maximum(base_sine, 0)\n",
    "\n",
    "    # current = np.repeat(current.reshape(1,-1), n_input_neurons, axis=0)\n",
    "\n",
    "     # Generate unique Gaussian noise for each neuron and add to sine wave\n",
    "    current = current\n",
    "\n",
    "\n",
    "    return current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5da885e4-7bf5-4c1c-864b-b1d77ded8a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_to_save = {}\n",
    "data_to_save[\"sine\"] = generate_input_sine(200, 1, 0.1)\n",
    "data_to_save[\"bump\"] = generate_input_bumps(300, 1, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8ac907-2b3e-4efb-afc0-4fdc559529dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "384a1203-61d4-4150-900b-9aab66db02c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "V_th_std_all = np.linspace(0, 2, 9)\n",
    "\n",
    "\n",
    "# Initialize lists to store values\n",
    "firing_means = []\n",
    "firing_stds = []\n",
    "\n",
    "dimensionality_values = []\n",
    "\n",
    "stim_rmse_means = []\n",
    "stim_rmse_stds = []\n",
    "network_rmse_means = []\n",
    "network_rmse_stds = []\n",
    "\n",
    "decoded_test_signal_network = None\n",
    "decoded_test_signal_stim = None\n",
    "\n",
    "V_th_repeated = None\n",
    "weights_flattened = None\n",
    "\n",
    "stim_rmse_means_gen = []\n",
    "stim_rmse_stds_gen = []\n",
    "network_rmse_means_gen = []\n",
    "network_rmse_stds_gen = []\n",
    "\n",
    "decoded_test_signal_network_gen = None\n",
    "decoded_test_signal_stim_gen = None\n",
    "\n",
    "for V_th_std in V_th_std_all:\n",
    "    filename = f'/Users/frazi/scripts/HLIF_7_mac/data/spikes_V_th_std_{V_th_std}_trial_{0}.pkl'\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "        \n",
    "    # Extract spike data\n",
    "    spikes = data['spikes']\n",
    "    stim_neuron_ids = data[\"input_1_neurons\"]\n",
    "\n",
    "    spike_matrix = spikes_to_matrix(spikes, 20000, 10000, 0.1)\n",
    "    mean_rate = (spike_matrix.sum(axis=0) / 2).mean()\n",
    "    std_rate = (spike_matrix.sum(axis=0) / 2).std()\n",
    "    \n",
    "    firing_means.append(mean_rate)\n",
    "    firing_stds.append(std_rate)\n",
    "\n",
    "    # Compute participation ratio\n",
    "    n_bins = 250  # Number of bins to sum over\n",
    "    spike_matrix_reduced = spike_matrix.reshape(-1, n_bins, spike_matrix.shape[1]).sum(axis=1)\n",
    "    dimensionality = compute_participation_ratio(spike_matrix_reduced)\n",
    "    dimensionality_values.append(dimensionality)\n",
    "\n",
    "\n",
    "\n",
    "    filename = f\"/Users/frazi/scripts/HLIF_7_mac/data/DECODING_V_th_std_{V_th_std}.pkl\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    stim_rmse_means.append(np.mean(data['test_rmse_stim']))\n",
    "    stim_rmse_stds.append(np.std(data['test_rmse_stim']))\n",
    "    network_rmse_means.append(np.mean(data['test_rmse_network']))\n",
    "    network_rmse_stds.append(np.std(data['test_rmse_network']))\n",
    "\n",
    "\n",
    "    \n",
    "    weights_stim = data[\"weights_stim\"]\n",
    "    weights_network = data[\"weights_network\"]\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if V_th_std == 2.0:\n",
    "        decoded_test_signal_stim = data[\"decoded_test_signal_stim\"]\n",
    "        decoded_test_signal_network = data[\"decoded_test_signal_network\"]\n",
    "\n",
    "\n",
    "\n",
    "        rng = [np.random.default_rng(np.random.SeedSequence(entropy=654321, spawn_key=(0, 0, 0, i))) for i in range(4)]\n",
    "        # Generate thresholds\n",
    "        V_th_mean = -55\n",
    "        V_th = generate_heterogeneous_thresholds(V_th_mean, V_th_std, 10000, rng[0])\n",
    "        # Repeat V_th for each trial\n",
    "        V_th_repeated = np.tile(V_th, 10)\n",
    "\n",
    "        weights_flattened = weights_network.flatten()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    # Load generalization data\n",
    "    filename = f\"/Users/frazi/scripts/HLIF_7_mac/data/spikes_generalization_V_th_std_{V_th_std}_trial_0.pkl\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        data = pickle.load(f)\n",
    "    \n",
    "    spike_data = data[\"spikes\"]\n",
    "    \n",
    "    # Convert spike data into spike matrices\n",
    "    spike_matrix = spikes_to_matrix(spike_data, 3000, 10000, 0.1)\n",
    "    \n",
    "    # Apply convolution with an exponential kernel to smooth spikes\n",
    "    tau = 10\n",
    "    kernel = np.exp(-np.arange(0, 5 * tau, 0.1) / tau)\n",
    "    filtered_spikes = np.array([fft_convolution_with_padding(spike_matrix[:, j], kernel) for j in range(10000)]).T\n",
    "\n",
    "    # Compute generalization RMSE\n",
    "    X_stim_gen = filtered_spikes[:, stim_neuron_ids]\n",
    "    X_network_gen = filtered_spikes\n",
    "    \n",
    "    rmse_stim = []\n",
    "    rmse_network = []\n",
    "    \n",
    "    for i in range(10):\n",
    "        y_pred_stim_gen = X_stim_gen.dot(weights_stim[i])\n",
    "        y_pred_network_gen = X_network_gen.dot(weights_network[i])\n",
    "        \n",
    "        rmse_stim.append(np.sqrt(np.mean((y_pred_stim_gen - data_to_save[\"bump\"]) ** 2)))\n",
    "        rmse_network.append(np.sqrt(np.mean((y_pred_network_gen - data_to_save[\"bump\"]) ** 2)))\n",
    "    \n",
    "    \n",
    "    stim_rmse_means_gen.append(np.mean(rmse_stim))\n",
    "    stim_rmse_stds_gen.append(np.std(rmse_stim))\n",
    "    network_rmse_means_gen.append(np.mean(rmse_network))\n",
    "    network_rmse_stds_gen.append(np.std(rmse_network))\n",
    "    \n",
    "\n",
    "    if V_th_std == 2.0:\n",
    "\n",
    "        decoded_test_signal_stim_gen = y_pred_stim_gen\n",
    "        decoded_test_signal_network_gen = y_pred_network_gen\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "data_to_save[\"V_th_std_all\"] = V_th_std_all\n",
    "data_to_save[\"firing_means\"] = firing_means\n",
    "data_to_save[\"firing_stds\"] = firing_stds\n",
    "\n",
    "\n",
    "data_to_save[\"dimensionality_values\"] = dimensionality_values\n",
    "\n",
    "\n",
    "data_to_save[\"stim_rmse_means\"] = stim_rmse_means\n",
    "data_to_save[\"stim_rmse_stds\"] = stim_rmse_stds\n",
    "data_to_save[\"network_rmse_means\"] = network_rmse_means\n",
    "data_to_save[\"network_rmse_stds\"] = network_rmse_stds\n",
    "data_to_save[\"decoded_test_signal_stim\"] = decoded_test_signal_stim\n",
    "data_to_save[\"decoded_test_signal_network\"] = decoded_test_signal_network\n",
    "\n",
    "\n",
    "data_to_save[\"V_th_repeated\"] = V_th_repeated\n",
    "data_to_save[\"weights_flattened\"] = weights_flattened\n",
    "\n",
    "\n",
    "data_to_save[\"stim_rmse_means_gen\"] = stim_rmse_means_gen\n",
    "data_to_save[\"stim_rmse_stds_gen\"] = stim_rmse_stds_gen\n",
    "data_to_save[\"network_rmse_means_gen\"] = network_rmse_means_gen\n",
    "data_to_save[\"network_rmse_stds_gen\"] = network_rmse_stds_gen\n",
    "data_to_save[\"decoded_test_signal_stim_gen\"] = decoded_test_signal_stim_gen\n",
    "data_to_save[\"decoded_test_signal_network_gen\"] = decoded_test_signal_network_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b2967ff6-daf6-4f15-919b-5902b625d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the plot data\n",
    "with open('./data/plot_data.pkl', 'wb') as f:\n",
    "    pickle.dump(data_to_save, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
